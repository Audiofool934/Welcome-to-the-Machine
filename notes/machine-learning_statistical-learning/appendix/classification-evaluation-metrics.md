### 5. Criterion on Classification (Evaluation Metrics)

逻辑回归模型（或**任何分类模型**）训练完成后，我们需要评估其性能。评估指标的选择至关重要，具体取决于特定问题及其背景。

---

#### **附注：分类评估指标详解**

本附注旨在深入介绍常用的分类评估指标，包括相关术语和实际计算示例。

**核心概念：混淆矩阵 (Confusion Matrix)**

大多数分类指标的基础是**混淆矩阵**。对于二元分类问题（例如，预测类别 0 和 1，或负类和正类），它是一个总结预测结果的表格：

|                               | 预测为: 负类/0 | 预测为: 正类/1 |
| :---------------------------- | :-------------: | :-------------: |
| **实际为: 负类/0**            |   真阴性 (TN)   |   假阳性 (FP)   |
| **实际为: 正类/1**            |   假阴性 (FN)   |   真阳性 (TP)   |

**术语解释:**

*   **真阳性 (TP / True Positive):**
    *   定义：模型正确预测为正类的样本数量 (实际为正类，预测也为正类)。
    *   *例如:* 垃圾邮件分类器正确地将一封垃圾邮件识别为垃圾邮件。

*   **真阴性 (TN / True Negative):**
    *   定义：模型正确预测为负类的样本数量 (实际为负类，预测也为负类)。
    *   *例如:* 垃圾邮件分类器正确地将一封正常邮件识别为非垃圾邮件。

*   **假阳性 (FP / False Positive) - 第一类错误 (Type I Error):**
    *   定义：模型错误预测为正类的负类样本数量 (实际为负类，但预测为正类)。
    *   *例如:* 垃圾邮件分类器错误地将一封正常邮件标记为垃圾邮件。
    *   影响：如果错误的肯定性预测导致不必要的操作（例如，阻止合法用户，不必要的医疗），则代价可能很高。

*   **假阴性 (FN / False Negative) - 第二类错误 (Type II Error):**
    *   定义：模型错误预测为负类的正类样本数量 (实际为正类，但预测为负类)。
    *   *例如:* 垃圾邮件分类器未能检测到一封垃圾邮件，使其进入了收件箱。
    *   影响：如果错误的否定性预测意味着错过了重要事件（例如，未能检测到疾病，错过欺诈性交易），则代价可能很高。

**常用评估指标:**

1.  **准确率 (Accuracy):**
    *   公式: $\text{准确率} = \frac{TP + TN}{\text{总样本数}} = \frac{TP + TN}{TP + TN + FP + FN}$
    *   解释：模型整体预测正确的样本占总样本的比例。
    *   优点：简单直观。
    *   缺点：对于**类别不平衡数据集 (imbalanced datasets)** 可能具有误导性。如果99%的数据属于A类，一个将所有样本都预测为A类的模型会获得99%的准确率，但对于B类则毫无用处。
        *   *例如:* 假设一个癌症检测模型，在1000个样本中，只有10个是癌症患者 (正类)，990个是健康人 (负类)。如果模型将所有人都预测为健康，那么 TN=990, FP=0, TP=0, FN=10。准确率 = (0+990)/(0+990+0+10) = 990/1000 = 99%。这个准确率很高，但模型完全没有识别出任何癌症患者，因此是一个无用的模型。

2.  **精确率 (Precision / 查准率 / Positive Predictive Value, PPV):**
    *   公式: $\text{精确率} = \frac{TP}{TP + FP}$ (即 $\frac{TP}{\text{模型预测为正类的总数}}$)
    *   解释：在所有被模型预测为正类的样本中，有多少是真正的正类？(关注预测为正的那些结果有多准。)
    *   适用场景：当假阳性 (FP) 的代价很高时。
        *   *例如:* 在推荐系统中，向用户推荐了一个他不感兴趣的内容 (FP)，用户体验会下降。我们希望推荐的内容尽可能精准。
        *   *例如:* 在垃圾邮件过滤中，将一封重要邮件错判为垃圾邮件 (FP) 的代价很高。

3.  **召回率 (Recall / 查全率 / Sensitivity / True Positive Rate, TPR):**
    *   公式: $\text{召回率} = \frac{TP}{TP + FN}$ (即 $\frac{TP}{\text{实际为正类的总数}}$)
    *   解释：在所有实际为正类的样本中，有多少被模型成功预测出来了？(关注模型能把多少真正的正类都找出来。)
    *   适用场景：当假阴性 (FN) 的代价很高时。
        *   *例如:* 在疾病诊断中，漏诊一个病人 (FN) 的代价可能非常高。
        *   *例如:* 在金融欺诈检测中，未能识别一笔欺诈交易 (FN) 会导致经济损失。

    **精确率-召回率权衡 (Precision-Recall Tradeoff):**
    通常，提高精确率可能会降低召回率，反之亦然。例如，如果一个模型在预测正类时变得更加保守（以减少FP并提高精确率），它可能会错过一些实际的正类（增加FN并降低召回率）。如何选择取决于具体的业务问题。

4.  **F1分数 (F1-Score):**
    *   公式: $F1 = 2 \cdot \frac{\text{精确率} \cdot \text{召回率}}{\text{精确率} + \text{召回率}} = \frac{2TP}{2TP + FP + FN}$
    *   解释：精确率和召回率的调和平均数。它提供了一个平衡两者的单一分数，在类别分布不均或需要平衡FP和FN成本时特别有用。
    *   F1分数会对极端值进行更大的惩罚。如果精确率或召回率中任何一个非常低，F1分数也会很低。

5.  **特异性 (Specificity / True Negative Rate, TNR):**
    *   公式: $\text{特异性} = \frac{TN}{TN + FP}$ (即 $\frac{TN}{\text{实际为负类的总数}}$)
    *   解释：在所有实际为负类的样本中，有多少被模型成功预测出来了？(与召回率/灵敏度互补)。
    *   适用场景：当正确识别负类至关重要时（例如，药物测试——确保无辜的人不被错误指控）。

6.  **假阳性率 (FPR / False Positive Rate):**
    *   公式: $\text{FPR} = \frac{FP}{FP + TN} = 1 - \text{特异性}$ (即 $\frac{FP}{\text{实际为负类的总数}}$)
    *   解释：实际为负类的样本中，被错误预测为正类的比例。用于ROC曲线。

7.  **ROC曲线 (Receiver Operating Characteristic Curve, ROC Curve):**
    *   定义：以假阳性率 (FPR) 为横坐标，真阳性率 (TPR / 召回率) 为纵坐标，绘制不同分类阈值下的点连接成的曲线。
    *   用途：可视化分类器在不同概率阈值（例如逻辑回归的概率阈值）下，其收益 (TPR) 与代价 (FPR) 之间的权衡。一个好的分类器的ROC曲线会尽量靠近左上角 (TPR=1, FPR=0)。

8.  **AUC (Area Under the ROC Curve / AUC值):**
    *   定义：ROC曲线下的面积。取值范围0到1。
    *   解释：一个综合衡量分类器在所有可能阈值下的性能的单一数值。可以理解为模型将随机选择的正样本排在随机选择的负样本前面的概率。
    *   AUC = 1: 完美分类器。
    *   AUC = 0.5: 随机猜测 (无区分能力)。
    *   AUC对于比较模型很有用，并且比准确率对类别不平衡问题不那么敏感。

9.  **对数损失 (Log Loss / Cross-Entropy Loss):**
    *   定义：衡量输出为0到1之间概率值的分类模型的性能。对数损失越低，表示模型的概率预测越好。它惩罚那些自信但错误的预测。
    *   解释：直接评估预测概率的质量。如果模型为正确类别预测了高概率，则损失较低。如果它为正确类别预测了低概率（或为错误类别预测了高概率），则损失较高。

**计算练习:**

**场景一:**
对100人进行了一项疾病的医学检测。
-   实际患病人数: 20
-   实际健康人数: 80
检测结果:
-   检测阳性且患病 (TP): 15
-   检测阳性但健康 (FP): 10
-   检测阴性但患病 (FN): 5
-   检测阴性且健康 (TN): 70

**混淆矩阵:**
|                 | 预测为: 健康 (阴性) | 预测为: 患病 (阳性) |
| :-------------- | :-----------------------: | :------------------------: |
| 实际为: 健康    |            TN = 70            |           FP = 10            |
| 实际为: 患病    |            FN = 5             |           TP = 15            |

**计算:**
1.  准确率 (Accuracy)
2.  精确率 (Precision)
3.  召回率 (Recall)
4.  F1分数 (F1-Score)
5.  特异性 (Specificity)
6.  假阳性率 (FPR)

**解答:**
1.  **准确率** = (TP + TN) / (TP + TN + FP + FN) = (15 + 70) / (15 + 70 + 10 + 5) = 85 / 100 = **0.85 (85%)**
2.  **精确率** = TP / (TP + FP) = 15 / (15 + 10) = 15 / 25 = **0.60 (60%)**
    *   (在所有被检测为阳性的人中，60% 的人确实患病。)
3.  **召回率** = TP / (TP + FN) = 15 / (15 + 5) = 15 / 20 = **0.75 (75%)**
    *   (在所有实际患病的人中，75% 的人被成功检测出来了。)
4.  **F1分数** = 2 * (精确率 * 召回率) / (精确率 + 召回率) = 2 * (0.60 * 0.75) / (0.60 + 0.75) = 2 * 0.45 / 1.35 = 0.90 / 1.35 ≈ **0.667**
5.  **特异性** = TN / (TN + FP) = 70 / (70 + 10) = 70 / 80 = **0.875 (87.5%)**
    *   (在所有实际健康的人中，87.5% 的人被正确检测为阴性。)
6.  **FPR** = FP / (FP + TN) = 10 / (10 + 70) = 10 / 80 = **0.125 (12.5%)**
    *   (在所有实际健康的人中，12.5% 的人被错误地检测为阳性。)

**场景二: 垃圾邮件过滤器**
处理了1000封邮件。
-   实际垃圾邮件: 100
-   实际正常邮件 (Not Spam): 900
过滤结果:
-   标记为垃圾邮件且为垃圾邮件 (TP): 90
-   标记为垃圾邮件但为正常邮件 (FP): 5  <-- 重要正常邮件被错误标记!
-   标记为正常邮件但为垃圾邮件 (FN): 10 <-- 垃圾邮件漏网!
-   标记为正常邮件且为正常邮件 (TN): 895

**挑战:**
计算准确率、精确率、召回率和F1值。对于这个垃圾邮件过滤器，哪些指标最重要？为什么？

**解答:**
**混淆矩阵:**
|             | 预测为: 正常邮件 | 预测为: 垃圾邮件 |
| :---------- | :--------------------: | :--------------------: |
| 实际: 正常邮件 |       TN = 895         |         FP = 5         |
| 实际: 垃圾邮件 |        FN = 10         |         TP = 90        |

1.  **准确率** = (90 + 895) / 1000 = 985 / 1000 = **0.985 (98.5%)**
2.  **精确率** = TP / (TP + FP) = 90 / (90 + 5) = 90 / 95 ≈ **0.947 (94.7%)**
3.  **召回率** = TP / (TP + FN) = 90 / (90 + 10) = 90 / 100 = **0.90 (90%)**
4.  **F1分数** = 2 * (0.947 * 0.90) / (0.947 + 0.90) = 2 * 0.8523 / 1.847 ≈ **0.923**

**最重要的指标:**
对于垃圾邮件过滤器，**精确率 (Precision)** 通常非常重要。因为将重要邮件 (Ham) 错误标记为垃圾邮件 (FP) 的代价很高，用户可能会因此错过关键信息。
同时，**召回率 (Recall)** 也很重要，因为我们希望尽可能多地捕获所有实际的垃圾邮件 (最小化 FN)，以减少漏网的垃圾邮件。
**F1分数 (F1-Score)** 在这里提供了一个很好的平衡。
尽管此处的准确率 (Accuracy) 很高，但它可能会产生误导，因为数据集存在类别不平衡问题 (900封正常邮件 vs. 100封垃圾邮件)。

---
**(附注结束)**

评估指标的选择在很大程度上取决于具体问题、业务目标和类别分布。例如，在欺诈检测（类别不平衡，假阴性代价高）中，召回率和F1分数可能比整体准确率更重要。
